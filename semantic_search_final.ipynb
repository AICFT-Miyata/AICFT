{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1QVrRbi1t5y5WGx7f-o2-ioZS7xzjI6Tf",
      "authorship_tag": "ABX9TyP7lbo9kQSn38KTG74qF++Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AICFT-Miyata/AICFT/blob/main/semantic_search_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. 必要なライブラリのインストールとインポート ---\n",
        "# 警告が出ますが、無視して処理を続行してください。\n",
        "\n",
        "# 1. 意味検索と言語処理用ライブラリ\n",
        "!pip install -qq fugashi ipadic unidic-lite sentence-transformers scikit-learn gspread\n",
        "\n",
        "# 2. GGUF実行に必要なllama-cpp-pythonをGPUサポート付きでインストール\n",
        "# ⚠️ インストールには時間がかかり、途中文字化けのような出力が出ますが、処理を中断しないでください。\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" FORCE_CMAKE=1 pip install -qq llama-cpp-python\n",
        "\n",
        "# --- ライブラリのインポート ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gspread\n",
        "import time\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "# GGUF用ライブラリ（ここでLlamaクラスを定義）\n",
        "try:\n",
        "    from llama_cpp import Llama\n",
        "    print(\"✅ Llama-cpp-pythonのインポートに成功しました。\")\n",
        "except ImportError:\n",
        "    # インストールが成功していれば、このエラーは出ないはず\n",
        "    print(\"❌ Llama-cpp-pythonのインポートに失敗しました。AI洗練機能は動作しません。\")\n",
        "    Llama = None # エラーハンドリングのためLlamaをNoneに設定\n",
        "\n",
        "# --- 1. 定数・初期設定 ---\n",
        "# ⚠️ 以下の3つのパス・名前をあなたの環境に合わせて最終修正してください\n",
        "SPREADSHEET_NAME = 'スプレッドシート作成検証'\n",
        "TARGET_SHEET = '検索入力シート'\n",
        "TRAINING_DATA_PATH = '/content/drive/MyDrive/AICFT/DB.csv'\n",
        "\n",
        "# ⚠️ GGUFモデルのパスを、あなたがアップロードした Q5_K_M のものに修正してください\n",
        "GGUF_MODEL_PATH = '/content/drive/MyDrive/AICFT/LLM_GGUF/llama3-8b-instruct-Q5_K_M.gguf'\n",
        "\n",
        "# モデルのロード (意味検索用)\n",
        "EMBEDDING_MODEL = SentenceTransformer('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "# GGUFモデルの初期設定 (AI洗練用)\n",
        "LLAMA_CLIENT = None\n",
        "if Llama:\n",
        "    try:\n",
        "        # モデルのロード（メモリ効率が良いQ5_K_MをGPUの全レイヤーで実行）\n",
        "        LLAMA_CLIENT = Llama(\n",
        "            model_path=GGUF_MODEL_PATH,\n",
        "            n_ctx=4096,\n",
        "            n_gpu_layers=-1,\n",
        "            verbose=False\n",
        "        )\n",
        "        print(\"✅ GGUFモデルのロードに成功しました。\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ GGUFモデルのロードに失敗しました。AI洗練機能は動作しません。エラー: {e}\")\n",
        "\n",
        "\n",
        "# --- 2. データの準備とエンベディング生成 ---\n",
        "def load_and_embed_data(file_path):\n",
        "    # ... (既存のコード。省略) ...\n",
        "    try:\n",
        "        df_train = pd.read_csv(file_path, encoding='utf-8', sep=',',\n",
        "             usecols=['階級', '目標（50～100文字）', '自己申告（50～100文字）', '上司コメント（50～100文字）'])\n",
        "        df_train.columns = ['Rank', 'Goal', 'SelfReport', 'SupervisorComment']\n",
        "        df_train['CombinedText'] = df_train['Goal'].astype(str) + \" [SEP] \" + df_train['SelfReport'].astype(str)\n",
        "        embeddings = EMBEDDING_MODEL.encode(df_train['CombinedText'].tolist(), convert_to_tensor=True)\n",
        "        return df_train, embeddings.cpu().numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"データ処理エラー: {e}\")\n",
        "        return None, None\n",
        "\n",
        "df_train, train_embeddings = load_and_embed_data(TRAINING_DATA_PATH)\n",
        "\n",
        "# --- 3. 検索ロジック ---\n",
        "def find_best_match_comment(input_goal, input_self_report):\n",
        "    # ... (既存のコード。省略) ...\n",
        "    if df_train is None:\n",
        "        return \"ERROR: Training data not loaded.\", 0.0\n",
        "    new_combined_text = str(input_goal) + \" [SEP] \" + str(input_self_report)\n",
        "    new_embedding = EMBEDDING_MODEL.encode(new_combined_text, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
        "    similarities = cosine_similarity(new_embedding, train_embeddings)[0]\n",
        "    best_match_index = np.argmax(similarities)\n",
        "    best_comment = df_train.iloc[best_match_index]['SupervisorComment']\n",
        "    return best_comment, similarities[best_match_index]\n",
        "\n",
        "\n",
        "# --- 5. AIによるコメント洗練ロジック (GGUF実行) ---\n",
        "def refine_comment_with_ai(input_goal, input_self_report, best_comment):\n",
        "    # ... (LLAMA_CLIENT is None のチェックは省略) ...\n",
        "\n",
        "    try:\n",
        "        print(\"--- AIによるコメント洗練開始 (LLaMA 3 GGUF) ---\")\n",
        "\n",
        "        # 修正：日本語での出力形式を強力に指定\n",
        "        system_prompt = \"あなたは人事評価の上司コメントを作成するAIです。日本語で、具体的で建設的なフィードバックを、簡潔に作成してください。\"\n",
        "\n",
        "        user_prompt = f\"\"\"\n",
        "        [入力データ]\n",
        "        目標: {input_goal}\n",
        "        自己申告: {input_self_report}\n",
        "        [推薦コメント (参考)]\n",
        "        {best_comment}\n",
        "\n",
        "        上記のデータを参照し、日本語で上司コメントを生成してください。出力はコメント本文のみとします。\n",
        "        \"\"\"\n",
        "\n",
        "        # 修正：応答開始を「日本語のコメント」の形式で始めるよう指示\n",
        "        prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{system_prompt}<|eot|><|start_header_id|>user<|end_header_id|>\\n{user_prompt}<|eot|><|start_header_id|>assistant<|end_header_id|>\\n**【上司コメント】**\"\n",
        "        # ↑ 応答の開始を明確に日本語の形式で始めるよう強制します\n",
        "\n",
        "        # 推論実行\n",
        "        output = LLAMA_CLIENT.create_completion(\n",
        "            prompt=prompt,\n",
        "            max_tokens=256,\n",
        "            temperature=0.4, # 創造性を少し下げ、指示に忠実になるように調整\n",
        "            stop=[\"<|eot|>\"]\n",
        "        )\n",
        "\n",
        "        # 応答から強制開始文字列を除去\n",
        "        refined_comment = output['choices'][0]['text'].replace('**【上司コメント】**', '').strip()\n",
        "        print(\"AI洗練コメント生成成功。\")\n",
        "        return refined_comment\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"AI洗練処理エラー。通常通り検索結果を出力します。エラー: {e}\")\n",
        "        return best_comment\n",
        "\n",
        "\n",
        "# --- 4. メイン処理 (Apps Scriptから実行される想定) ---\n",
        "def main_search_and_write():\n",
        "    if df_train is None:\n",
        "        print(\"検索スキップ: 訓練データなし\")\n",
        "        return \"検索スキップ: 訓練データなし\", 0.0\n",
        "\n",
        "    print(\"--- gspread認証開始 ---\")\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    creds, _ = google.auth.default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    spreadsheet = gc.open(SPREADSHEET_NAME)\n",
        "    input_sheet = spreadsheet.worksheet(TARGET_SHEET)\n",
        "\n",
        "    data_list = input_sheet.get('B1:E1', value_render_option='UNFORMATTED_VALUE')\n",
        "\n",
        "    if not data_list or len(data_list[0]) < 4:\n",
        "        print(\"ERROR: スプレッドシートのB1～E1範囲にデータが不足しています。処理を中断します。\")\n",
        "        return \"ERROR: データ不足\", 0.0\n",
        "\n",
        "    input_data = data_list[0]\n",
        "    input_goal = input_data[0]\n",
        "    input_self_report = input_data[3]\n",
        "\n",
        "    print(f\"入力データ: 目標='{input_goal}', 自己申告='{input_self_report}'\")\n",
        "\n",
        "    # 1. 意味検索実行\n",
        "    best_comment, similarity_score = find_best_match_comment(input_goal, input_self_report)\n",
        "    print(f\"検索結果 (原案): {best_comment}\")\n",
        "\n",
        "    # 2. AI洗練 (LLM連携)\n",
        "    final_comment = refine_comment_with_ai(input_goal, input_self_report, best_comment)\n",
        "\n",
        "    # 3. 結果をスプレッドシートに出力\n",
        "    input_sheet.update('F1', [[final_comment]])\n",
        "    input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n",
        "    print(f\"最終結果 (F1) を出力完了。類似度: {similarity_score:.4f}\")\n",
        "\n",
        "    return final_comment, similarity_score\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 単体テストとしてメイン処理を実行\n",
        "    main_search_and_write()\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb-BZacpGGw1",
        "outputId": "8a27f5fb-5b85-4e70-878c-a9337f523a0c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Llama-cpp-pythonのインポートに成功しました。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name cl-tohoku/bert-base-japanese-whole-word-masking. Creating a new one with mean pooling.\n",
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GGUFモデルのロードに成功しました。\n",
            "--- gspread認証開始 ---\n",
            "入力データ: 目標='積極的にワークライフバランスに努める', 自己申告='テレワークを５回実施した。'\n",
            "検索結果 (原案): 科学的なアプローチによる隊員能力の維持向上に貢献した。プログラムの継続的な効果測定と、他の部隊への展開を検討すべき。\n",
            "--- AIによるコメント洗練開始 (LLaMA 3 GGUF) ---\n",
            "AI洗練コメント生成成功。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1693090277.py:164: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  input_sheet.update('F1', [[final_comment]])\n",
            "/tmp/ipython-input-1693090277.py:165: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終結果 (F1) を出力完了。類似度: 0.8999\n"
          ]
        }
      ]
    }
  ]
}