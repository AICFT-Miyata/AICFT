{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1QVrRbi1t5y5WGx7f-o2-ioZS7xzjI6Tf",
      "authorship_tag": "ABX9TyPTM07RVI4lgSBUop8qd+n7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AICFT-Miyata/AICFT/blob/main/semantic_search_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fugashi ipadic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5rfN0kHgugV",
        "outputId": "3df041e2-7365-4437-dcb3-364dd661d986"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fugashi\n",
            "  Downloading fugashi-1.5.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading fugashi-1.5.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (694 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.9/694.9 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=9c7e0de20d5dd9e0f9ffdc8c8982177d51449ca4d336aa1770753da36456fa1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/8b/55/dd5978a069678c372520847cf84ba2ec539cb41917c00a2206\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic, fugashi\n",
            "Successfully installed fugashi-1.5.2 ipadic-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidic-lite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b03I51Qtg_T5",
        "outputId": "28d7b1dc-7349-4a82-ee34-9421af439cbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidic-lite\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unidic-lite\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658817 sha256=c1d97848452e03a123d5d8ad6eaf92ca33ef049e199c7e0ce54f8fc9ab852dfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/1f/0f/4d43887e5476d956fae828ee9b6687becd5544d68b51ed633d\n",
            "Successfully built unidic-lite\n",
            "Installing collected packages: unidic-lite\n",
            "Successfully installed unidic-lite-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsu2k8AhoAq2",
        "outputId": "fbd96eab-71cd-4d01-cca2-0e9921600008"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.49.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_O8G8xyf0lZ",
        "outputId": "71f485a8-8029-425a-c1c4-772b34fa2352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name cl-tohoku/bert-base-japanese-whole-word-masking. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- gspread認証開始 ---\n",
            "入力データ: 目標='積極的にワークライフバランスに努める', 自己申告='テレワークを５回実施した。'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3421670774.py:80: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  input_sheet.update('F1', [[comment]])\n",
            "/tmp/ipython-input-3421670774.py:83: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検索結果をF1に出力完了。類似度: 0.8999\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gspread # スプレッドシートへの書き込み用\n",
        "import time\n",
        "\n",
        "# --- 1. 定数・初期設定 ---\n",
        "# ⚠️ ここをあなたの環境に合わせて修正してください\n",
        "SPREADSHEET_NAME = 'スプレッドシート作成検証'\n",
        "TARGET_SHEET = '検索入力シート' # VBAから入力が行われるシート名\n",
        "TRAINING_DATA_PATH = '/content/drive/MyDrive/AICFT/DB.csv'\n",
        "\n",
        "# モデルのロード (以前成功した軽量モデル)\n",
        "EMBEDDING_MODEL = SentenceTransformer('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "# --- 2. データの準備とエンベディング生成 ---\n",
        "def load_and_embed_data(file_path):\n",
        "    try:\n",
        "        # CP932でファイルを読み込み、必要なカラムのみを選択\n",
        "        df_train = pd.read_csv(file_path, encoding='utf-8', sep=',',\n",
        "          usecols=['階級', '目標（50～100文字）', '自己申告（50～100文字）', '上司コメント（50～100文字）'])\n",
        "        df_train.columns = ['Rank', 'Goal', 'SelfReport', 'SupervisorComment']\n",
        "        df_train['CombinedText'] = df_train['Goal'].astype(str) + \" [SEP] \" + df_train['SelfReport'].astype(str)\n",
        "\n",
        "        # エンベディング生成\n",
        "        embeddings = EMBEDDING_MODEL.encode(df_train['CombinedText'].tolist(), convert_to_tensor=True)\n",
        "        return df_train, embeddings.cpu().numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"データ処理エラー: {e}\")\n",
        "        return None, None\n",
        "\n",
        "df_train, train_embeddings = load_and_embed_data(TRAINING_DATA_PATH)\n",
        "\n",
        "# --- 3. 検索ロジック ---\n",
        "def find_best_match_comment(input_goal, input_self_report):\n",
        "    if df_train is None:\n",
        "        return \"ERROR: Training data not loaded.\", 0.0\n",
        "    new_combined_text = str(input_goal) + \" [SEP] \" + str(input_self_report)\n",
        "    new_embedding = EMBEDDING_MODEL.encode(new_combined_text, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
        "    similarities = cosine_similarity(new_embedding, train_embeddings)[0]\n",
        "    best_match_index = np.argmax(similarities)\n",
        "    best_comment = df_train.iloc[best_match_index]['SupervisorComment']\n",
        "    return best_comment, similarities[best_match_index]\n",
        "\n",
        "\n",
        "# --- 4. メイン処理 (Apps Scriptから実行される想定) ---\n",
        "def main_search_and_write():\n",
        "    if df_train is None:\n",
        "        print(\"検索スキップ: 訓練データなし\")\n",
        "        return \"検索スキップ: 訓練データなし\", 0.0\n",
        "\n",
        "    print(\"--- gspread認証開始 ---\")\n",
        "    # Colabでの認証画面を表示するための処理\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    # 認証情報をgspreadに渡す (Colab推奨形式への修正)\n",
        "    import google.auth # 新しくインポートを追加\n",
        "\n",
        "    # 認証情報を取得\n",
        "    creds, _ = google.auth.default()\n",
        "\n",
        "    # 認証情報を使ってgspreadを初期化\n",
        "    gc = gspread.authorize(creds)\n",
        "    spreadsheet = gc.open(SPREADSHEET_NAME)\n",
        "    input_sheet = spreadsheet.worksheet(TARGET_SHEET)\n",
        "\n",
        "    # スプレッドシートから入力データを読み込み (B1: 目標, E1: 自己申告)\n",
        "    input_data = input_sheet.get('B1:E1', value_render_option='UNFORMATTED_VALUE')[0]\n",
        "    input_goal = input_data[0]\n",
        "    input_self_report = input_data[3]\n",
        "\n",
        "    print(f\"入力データ: 目標='{input_goal}', 自己申告='{input_self_report}'\")\n",
        "\n",
        "    # 検索実行\n",
        "    comment, similarity_score = find_best_match_comment(input_goal, input_self_report)\n",
        "\n",
        "# 結果をスプレッドシートの F1 セルに出力 (データをリストのリスト形式に変更)\n",
        "    input_sheet.update('F1', [[comment]])\n",
        "\n",
        "    # G1 セルに出力\n",
        "    input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n",
        "    print(f\"検索結果をF1に出力完了。類似度: {similarity_score:.4f}\")\n",
        "\n",
        "    return comment, similarity_score\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 単体テストとして実行\n",
        "    main_search_and_write()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. AIによるコメント洗練ロジック (ラッキーテスト) ---\n",
        "def refine_comment_with_ai(input_goal, input_self_report, best_comment):\n",
        "    try:\n",
        "        print(\"--- AIによるコメント洗練開始 ---\")\n",
        "        # ⚠️ ラッキーテスト：APIキー不要のアクセスを試みます\n",
        "        # 成功しなかった場合は、次のエラー (NameError/APIError) で止まります\n",
        "        from google import genai\n",
        "\n",
        "        # 認証（authenticate_userで得られた認証情報を使えるか試みる）\n",
        "        # ただし、通常はAPIキーが必要\n",
        "        client = genai.Client()\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        あなたは、人事評価の上司コメントを作成するAIです。\n",
        "        以下の[入力データ]に基づき、[推薦コメント]を参考にしながら、より個性的で具体的、かつ前向きな「上司コメント」を日本語で作成してください。\n",
        "        出力は洗練されたコメント本文のみとしてください。\n",
        "\n",
        "        [入力データ]\n",
        "        目標: {input_goal}\n",
        "        自己申告: {input_self_report}\n",
        "\n",
        "        [推薦コメント]\n",
        "        {best_comment}\n",
        "        \"\"\"\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.5-flash', # 高速な軽量モデルを使用\n",
        "            contents=prompt,\n",
        "            # temperature=0.7 # コメント生成には創造性を許容\n",
        "        )\n",
        "\n",
        "        refined_comment = response.text.strip()\n",
        "        print(\"AI洗練コメント生成成功。\")\n",
        "        return refined_comment\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"AI洗練エラー。通常通り検索結果を出力します。エラー: {e}\")\n",
        "        return best_comment # エラー時は検索結果をそのまま返す\n",
        "\n",
        "# --- 4. メイン処理 (既存の main_search_and_write を修正) ---\n",
        "# 既存の main_search_and_write 関数全体をこの新しいバージョンに置き換えてください\n",
        "def main_search_and_write():\n",
        "    if df_train is None:\n",
        "        print(\"検索スキップ: 訓練データなし\")\n",
        "        return \"検索スキップ: 訓練データなし\", 0.0\n",
        "\n",
        "    print(\"--- gspread認証開始 ---\")\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    import google.auth\n",
        "    creds, _ = google.auth.default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    spreadsheet = gc.open(SPREADSHEET_NAME)\n",
        "    input_sheet = spreadsheet.worksheet(TARGET_SHEET)\n",
        "\n",
        "    data_list = input_sheet.get('B1:E1', value_render_option='UNFORMATTED_VALUE')\n",
        "    if not data_list or len(data_list[0]) < 4:\n",
        "        print(\"ERROR: スプレッドシートのB1～E1範囲にデータが不足しています。処理を中断します。\")\n",
        "        return \"ERROR: データ不足\", 0.0\n",
        "\n",
        "    input_data = data_list[0]\n",
        "    input_goal = input_data[0]\n",
        "    input_self_report = input_data[3]\n",
        "\n",
        "    print(f\"入力データ: 目標='{input_goal}', 自己申告='{input_self_report}'\")\n",
        "\n",
        "    # 1. 検索実行\n",
        "    best_comment, similarity_score = find_best_match_comment(input_goal, input_self_report)\n",
        "    print(f\"検索結果 (原案): {best_comment}\")\n",
        "\n",
        "    # 2. AI洗練 (追加ステップ)\n",
        "    final_comment = refine_comment_with_ai(input_goal, input_self_report, best_comment)\n",
        "\n",
        "    # 3. 結果をスプレッドシートに出力\n",
        "    input_sheet.update('F1', [[final_comment]])\n",
        "    input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n",
        "    print(f\"最終結果 (F1) を出力完了。類似度: {similarity_score:.4f}\")\n",
        "\n",
        "    return final_comment, similarity_score"
      ],
      "metadata": {
        "id": "vVIkm9OenupE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. 必要なライブラリのインストール ---\n",
        "# 警告が出ますが、無視して処理を続行してください。\n",
        "!pip install -qq fugashi ipadic unidic-lite\n",
        "!pip install -qq google-genai\n",
        "\n",
        "# --- ライブラリのインポート ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gspread # スプレッドシートへの書き込み用\n",
        "import time\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "try:\n",
        "    from google import genai\n",
        "except ImportError:\n",
        "    print(\"Warning: google-genaiのインポートに失敗しました。AI洗練機能は動作しません。\")\n",
        "\n",
        "\n",
        "# --- 1. 定数・初期設定 ---\n",
        "# ⚠️ ここをあなたの環境に合わせて修正してください\n",
        "SPREADSHEET_NAME = 'スプレッドシート作成検証'  # 正しいスプレッドシート名\n",
        "TARGET_SHEET = '検索入力シート' # VBAから入力が行われるシート名\n",
        "TRAINING_DATA_PATH = '/content/drive/MyDrive/AICFT/DB.csv' # 正しいDBファイルパス\n",
        "\n",
        "# モデルのロード (以前成功した軽量モデル)\n",
        "EMBEDDING_MODEL = SentenceTransformer('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "# --- 2. データの準備とエンベディング生成 ---\n",
        "def load_and_embed_data(file_path):\n",
        "    try:\n",
        "        # 訓練データ（知識ベース）の読み込み\n",
        "        df_train = pd.read_csv(file_path, encoding='utf-8', sep=',',\n",
        "             usecols=['階級', '目標（50～100文字）', '自己申告（50～100文字）', '上司コメント（50～100文字）'])\n",
        "        df_train.columns = ['Rank', 'Goal', 'SelfReport', 'SupervisorComment']\n",
        "\n",
        "        # 検索対象となる結合文章を作成\n",
        "        df_train['CombinedText'] = df_train['Goal'].astype(str) + \" [SEP] \" + df_train['SelfReport'].astype(str)\n",
        "\n",
        "        # エンベディング生成\n",
        "        embeddings = EMBEDDING_MODEL.encode(df_train['CombinedText'].tolist(), convert_to_tensor=True)\n",
        "        return df_train, embeddings.cpu().numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"データ処理エラー: {e}\")\n",
        "        return None, None\n",
        "\n",
        "df_train, train_embeddings = load_and_embed_data(TRAINING_DATA_PATH)\n",
        "\n",
        "# --- 3. 検索ロジック ---\n",
        "def find_best_match_comment(input_goal, input_self_report):\n",
        "    if df_train is None:\n",
        "        return \"ERROR: Training data not loaded.\", 0.0\n",
        "\n",
        "    new_combined_text = str(input_goal) + \" [SEP] \" + str(input_self_report)\n",
        "    new_embedding = EMBEDDING_MODEL.encode(new_combined_text, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
        "\n",
        "    similarities = cosine_similarity(new_embedding, train_embeddings)[0]\n",
        "    best_match_index = np.argmax(similarities)\n",
        "    best_comment = df_train.iloc[best_match_index]['SupervisorComment']\n",
        "\n",
        "    return best_comment, similarities[best_match_index]\n",
        "\n",
        "\n",
        "# --- 5. AIによるコメント洗練ロジック (ラッキーテスト) ---\n",
        "def refine_comment_with_ai(input_goal, input_self_report, best_comment):\n",
        "    try:\n",
        "        print(\"--- AIによるコメント洗練開始 (Gemini試行) ---\")\n",
        "        client = genai.Client() # APIキーなしでのアクセスを試みる\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        あなたは、人事評価の上司コメントを作成するAIです。\n",
        "        以下の[入力データ]に基づき、[推薦コメント]を参考にしながら、より個性的で具体的、かつ前向きな「上司コメント」を日本語で作成してください。\n",
        "        出力は洗練されたコメント本文のみとしてください。\n",
        "\n",
        "        [入力データ]\n",
        "        目標: {input_goal}\n",
        "        自己申告: {input_self_report}\n",
        "\n",
        "        [推薦コメント]\n",
        "        {best_comment}\n",
        "        \"\"\"\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.5-flash',\n",
        "            contents=prompt,\n",
        "        )\n",
        "\n",
        "        refined_comment = response.text.strip()\n",
        "        print(\"AI洗練コメント生成成功。\")\n",
        "        return refined_comment\n",
        "\n",
        "    except Exception as e:\n",
        "        # APIアクセス失敗時は、検索結果をそのまま返す\n",
        "        print(f\"AI洗練エラー。通常通り検索結果を出力します。エラー: {e}\")\n",
        "        return best_comment\n",
        "\n",
        "# --- 5. AIによるコメント洗練ロジック (関数全体を削除します) ---\n",
        "# def refine_comment_with_ai(...):\n",
        "#     ...\n",
        "\n",
        "# --- 4. メイン処理 (Apps Scriptから実行される想定) ---\n",
        "def main_search_and_write():\n",
        "    if df_train is None:\n",
        "        print(\"検索スキップ: 訓練データなし\")\n",
        "        return \"検索スキップ: 訓練データなし\", 0.0\n",
        "\n",
        "    print(\"--- gspread認証開始 ---\")\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    # 認証情報を取得し、gspreadを初期化\n",
        "    creds, _ = google.auth.default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    spreadsheet = gc.open(SPREADSHEET_NAME)\n",
        "    input_sheet = spreadsheet.worksheet(TARGET_SHEET)\n",
        "\n",
        "    # スプレッドシートから入力データを読み込み (B1: 目標, E1: 自己申告)\n",
        "    data_list = input_sheet.get('B1:E1', value_render_option='UNFORMATTED_VALUE')\n",
        "\n",
        "    if not data_list or len(data_list[0]) < 4:\n",
        "        print(\"ERROR: スプレッドシートのB1～E1範囲にデータが不足しています。処理を中断します。\")\n",
        "        return \"ERROR: データ不足\", 0.0\n",
        "\n",
        "    input_data = data_list[0]\n",
        "    input_goal = input_data[0]\n",
        "    input_self_report = input_data[3]\n",
        "\n",
        "    print(f\"入力データ: 目標='{input_goal}', 自己申告='{input_self_report}'\")\n",
        "\n",
        "    # 1. 意味検索実行\n",
        "    final_comment, similarity_score = find_best_match_comment(input_goal, input_self_report)\n",
        "    print(f\"検索結果: {final_comment}\")\n",
        "\n",
        "    # 2. 結果をスプレッドシートに出力\n",
        "    input_sheet.update('F1', [[final_comment]])\n",
        "    input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n",
        "    print(f\"最終結果 (F1) を出力完了。類似度: {similarity_score:.4f}\")\n",
        "\n",
        "    return final_comment, similarity_score\n",
        "\n",
        "# ... (続くコードは変更なし)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 単体テストとしてメイン処理を実行\n",
        "    main_search_and_write()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33jOp3miobj8",
        "outputId": "aba9c83c-cf5d-481c-bae7-9b1537b22b07"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name cl-tohoku/bert-base-japanese-whole-word-masking. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- gspread認証開始 ---\n",
            "入力データ: 目標='積極的にワークライフバランスに努める', 自己申告='テレワークを５回実施した。'\n",
            "検索結果: 科学的なアプローチによる隊員能力の維持向上に貢献した。プログラムの継続的な効果測定と、他の部隊への展開を検討すべき。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4161856309.py:136: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  input_sheet.update('F1', [[final_comment]])\n",
            "/tmp/ipython-input-4161856309.py:137: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  input_sheet.update('G1', [[f\"類似度: {similarity_score:.4f}\"]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終結果 (F1) を出力完了。類似度: 0.8999\n"
          ]
        }
      ]
    }
  ]
}